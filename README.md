# ğŸŒ OpenNanoScaleLLM

**OpenNanoScaleLLM** is a cleanâ€‘room, openâ€‘source **nanoâ€‘scale Large Language Model (LLM)** inspired by the *ideas* behind Googleâ€™s internal smallâ€‘model research â€” but built **entirely in the open**, using Hugging Face Transformers.

It is designed to be **small, fast, infraâ€‘aware, toolâ€‘aware, and explainable**, not just fluent.

> This is not a toy fineâ€‘tune. It is a full, endâ€‘toâ€‘end LLM system with training, RAG, tools, evaluation, and live demos.

---

## ğŸš€ Why OpenNanoScaleLLM Exists

There is **no openâ€‘source Google NanoBanana**:

* No public repo
* No weights
* No training code

That creates a gap.

**OpenNanoScaleLLM fills that gap** with:

* A real nanoâ€‘LLM (â‰ˆ1.5B params)
* Infrastructure & DevOps specialization
* Retrievalâ€‘Augmented Generation (RAG)
* Toolâ€‘aware reasoning to prevent hallucinations
* Transparent evaluation metrics

All built in a **cleanâ€‘room**, reproducible way.

---

## ğŸ§  Core Design Goals

* ğŸ§© **Nanoâ€‘scale** â€“ runs on modest GPUs / CPU when quantized
* âš¡ **Fast inference** â€“ LoRA + efficient base model
* ğŸ¯ **Domainâ€‘specialized** â€“ cloud, DevOps, Linux, APIs
* ğŸ” **Grounded answers** â€“ RAG + context checks
* ğŸ› ï¸ **Toolâ€‘aware** â€“ asks for logs, regions, APIs when needed
* ğŸ”“ **Fully open** â€“ Apacheâ€‘2.0 license

---

## ğŸ“ Model Overview

| Attribute      | Value                     |
| -------------- | ------------------------- |
| Base model     | Qwen2.5-1.5B            |
| Parameters     | ~1.5B                     |
| Fineâ€‘tuning    | LoRA (SFT)                |
| Context length | 4k tokens                 |
| License        | Apacheâ€‘2.0                |
| Library        | Hugging Face Transformers |

---

## ğŸ—ï¸ Repository Structure

```text
Open-NanoScale-LLM/
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ model.yaml
â”‚   â”œâ”€â”€ training.yaml
â”‚   â””â”€â”€ lora.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ devops_notes.md
â”‚   â”‚   â”œâ”€â”€ docker_errors.md
â”‚   â”‚   â””â”€â”€ k8s_troubleshooting.md
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ instructions.jsonl
â”‚   â”‚   â”œâ”€â”€ rag_chunks.jsonl
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ samples.jsonl
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ prepare_data.py
â”‚   â”œâ”€â”€ train_lora.py
â”‚   â”œâ”€â”€ merge_lora.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â”œâ”€â”€ prompt.py
â”‚   â””â”€â”€ qa.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ aws.py
â”‚   â”œâ”€â”€ logs.py
â”‚   â””â”€â”€ api.py
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ rag_engine.py
â”‚   â””â”€â”€ schemas.py
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ gradio_app.py
â”œâ”€â”€ evals/
â”‚   â”œâ”€â”€ test_cases.json
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ run_eval.py
â””â”€â”€ dashboard/
    â””â”€â”€ gradio_eval.py
```

---

## ğŸ§± ASCII Architecture Diagram (README-friendly)

This works perfectly in `README.md` and GitHub renders it cleanly.

```text
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚        User / Client       â”‚
                         â”‚  (CLI, Gradio, FastAPI)    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   OpenNanoScaleLLM Engine â”‚
                         â”‚  (Inference Orchestrator) â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚                       â”‚                       â”‚
               â–¼                       â–¼                       â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Tool Prechecks  â”‚   â”‚   RAG Retriever     â”‚   â”‚  Prompt Builder â”‚
     â”‚ (AWS / Logs /   â”‚   â”‚ (FAISS / Chroma)    â”‚   â”‚  System + Rules â”‚
     â”‚  API Context)   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚                        â”‚
              â”‚                        â–¼                        â”‚
              â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
              â”‚           â”‚   Vector Embeddings    â”‚            â”‚
              â”‚           â”‚ (MiniLM / SBERT)       â”‚            â”‚
              â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
              â”‚                       â”‚                         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  OpenNanoBanana LLM       â”‚
                         â”‚ (TinyLlama + LoRA)        â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚      Final Response        â”‚
                         â”‚  (Grounded + Tool-aware)  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ SVG Architecture Diagram (for blog / HF / portfolio)

```svg
<svg width="900" height="620" xmlns="http://www.w3.org/2000/svg">
  <style>
    .box { fill:#f9fafb; stroke:#111827; stroke-width:1.5; rx:8; ry:8; }
    .text { font-family:Arial, sans-serif; font-size:13px; fill:#111827; }
    .arrow { stroke:#111827; stroke-width:1.4; marker-end:url(#arrowhead); }
  </style>

  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7"
      refX="10" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#111827"/>
    </marker>
  </defs>

  <!-- User -->
  <rect x="350" y="20" width="200" height="50" class="box"/>
  <text x="390" y="50" class="text">User / Client</text>

  <!-- Engine -->
  <rect x="320" y="100" width="260" height="60" class="box"/>
  <text x="350" y="135" class="text">OpenNanoBanana Engine</text>

  <!-- Tools -->
  <rect x="60" y="220" width="220" height="60" class="box"/>
  <text x="85" y="255" class="text">Tool Prechecks (AWS / Logs / API)</text>

  <!-- RAG -->
  <rect x="340" y="220" width="220" height="60" class="box"/>
  <text x="375" y="255" class="text">RAG Retriever</text>

  <!-- Prompt -->
  <rect x="620" y="220" width="220" height="60" class="box"/>
  <text x="650" y="255" class="text">Prompt Builder</text>

  <!-- LLM -->
  <rect x="320" y="350" width="260" height="60" class="box"/>
  <text x="345" y="385" class="text">TinyLlama + LoRA (LLM)</text>

  <!-- Output -->
  <rect x="350" y="460" width="200" height="50" class="box"/>
  <text x="385" y="490" class="text">Final Answer</text>

  <!-- Arrows -->
  <line x1="450" y1="70" x2="450" y2="100" class="arrow"/>
  <line x1="450" y1="160" x2="170" y2="220" class="arrow"/>
  <line x1="450" y1="160" x2="450" y2="220" class="arrow"/>
  <line x1="450" y1="160" x2="730" y2="220" class="arrow"/>
  <line x1="170" y1="280" x2="450" y2="350" class="arrow"/>
  <line x1="450" y1="280" x2="450" y2="350" class="arrow"/>
  <line x1="730" y1="280" x2="450" y2="350" class="arrow"/>
  <line x1="450" y1="410" x2="450" y2="460" class="arrow"/>
</svg>

```

---

## ğŸ§ª Training Pipeline

### 1ï¸âƒ£ Dataset

Instructionâ€‘style JSONL focused on **infra reasoning**:

* AWS IAM, EC2, S3, ECR
* Docker & Kubernetes
* CI/CD failures
* API debugging

Example:

```json
{
  "instruction": "Why does an EC2 instance fail to access S3?",
  "input": "AccessDenied error",
  "output": "The EC2 instance likely lacks an IAM role or the attached policy does not allow s3:GetObject..."
}
```

---

### 2ï¸âƒ£ Data Preparation

```bash
python scripts/prepare_data.py
```

Formats data into a modelâ€‘friendly instruction template.

---

### 3ï¸âƒ£ LoRA Fineâ€‘Tuning

```bash
python scripts/train_lora.py
```

* Efficient
* Low VRAM
* Domainâ€‘focused

---

### 4ï¸âƒ£ Merge LoRA

```bash
python scripts/merge_lora.py
```

Produces a standalone model for inference & upload.

---

## ğŸ” Retrievalâ€‘Augmented Generation (RAG)

OpenNanoBanana is **RAGâ€‘first**, not RAGâ€‘boltedâ€‘on.

### RAG Flow

```
User Question
   â†“
Preâ€‘check (tools)
   â†“
Vector Retrieval (FAISS)
   â†“
Context Assembly
   â†“
Prompt Injection
   â†“
LLM Answer
```

### Knowledge Sources

* Markdown / PDF docs
* Cloud & DevOps references
* Userâ€‘supplied documents

Ingest once:

```bash
python rag/ingest.py
```

Run interactive QA:

```bash
python rag/qa.py
```

---

## ğŸ› ï¸ Toolâ€‘Aware Reasoning (Antiâ€‘Hallucination)

Instead of guessing, the model **asks for missing info**.

### Builtâ€‘in Tool Signals

* **AWS** â†’ asks for region, account, service
* **Logs** â†’ requests error logs
* **API** â†’ asks for endpoint, auth, method

Example:

> **User:** EC2 cannot pull image from ECR
> **Model:** Please confirm the AWS region and ensure the EC2 IAM role has `ecr:GetAuthorizationToken` permission.

This is intentional and by design.

---

## ğŸ“Š Evaluation & Hallucination Metrics

Most projects skip this. OpenNanoBanana doesnâ€™t.

### Metrics Implemented

* **Keyword Coverage** â€“ expected technical concepts
* **Groundedness** â€“ answer vs retrieved context
* **Hallucination Score** â€“ unsupported content
* **Refusal Correctness** â€“ asks for info instead of guessing

Run batch evaluation:

```bash
python evals/run_eval.py
```

### Visual Dashboard

```bash
python dashboard/gradio_eval.py
```

Shows:

* Perâ€‘question scores
* Hallucination trends
* Grounding quality

---

## ğŸŒ Live Demo

### Backend (FastAPI)

```bash
uvicorn app.main:app --reload
```

### Frontend (Gradio)

```bash
python ui/gradio_app.py
```

A real, productionâ€‘style LLM demo â€” not a notebook.

---

## ğŸ¤— Hugging Face Release

* **Model**: `hf.co/<Naveenub>/Open-NanoScale-LLM`
* **Live Space**: `hf.co/spaces/<Naveenub>/Open-NanoScale-LLM-demo`

Includes:

* Model card
* License
* Demo UI

---

## âš–ï¸ License

Apache License 2.0

You are free to:

* Use commercially
* Modify
* Redistribute

---

## âš ï¸ Disclaimer

This project is a **cleanâ€‘room, independent openâ€‘source implementation**.

* Not affiliated with Google
* Not derived from any proprietary NanoBanana system
* No private or restricted data used

---

## ğŸ¯ Who This Is For

* LLM / AI Engineers
* Infra & DevOps Engineers exploring AI
* Researchers interested in smallâ€‘model systems
* Anyone tired of hypeâ€‘only LLM repos

---

## ğŸ›£ï¸ Roadmap

* Multiâ€‘knowledgeâ€‘base RAG
* GGUF / Ollama packaging
* Tool execution (not just awareness)
* Deterministic infra mode

---

## â­ Final Note

OpenNanoBanana is meant to be:

* Readable
* Reproducible
* Honest
* Useful

If you build on it â€” ship it. ğŸŒğŸš€
