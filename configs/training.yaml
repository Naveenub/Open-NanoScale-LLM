epochs: 3
batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 2e-4
fp16: true
logging_steps: 10
save_steps: 500
output_dir: onb-lora
